{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "ExpStats = namedtuple('Stats', ['train_X_Y', 'train_X', 'train_Y', 'train_Y_X',\n",
    "                             'test_X_Y', 'test_X', 'test_Y', 'test_Y_X',\n",
    "                            'acc_mpe', 'ham_mpe', 'ext_mpe',\n",
    "                            'acc_marg', 'ham_marg', 'ext_marg'])\n",
    "\n",
    "USE_NOTEBOOK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_ll_from_log(log_str, ll_prefix='Train:', n_folds=5, newline='\\n'):\n",
    "    \n",
    "    p_X_Y_lls = []\n",
    "    p_X_lls = []\n",
    "    p_Y_lls = []\n",
    "    p_Y_X_lls = []\n",
    "    \n",
    "    lines = log_str.split(newline)\n",
    "    for line in lines:\n",
    "        if ll_prefix in line:\n",
    "            stats = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "            assert len(stats) == 4\n",
    "            \n",
    "            p_X_Y_lls.append(float(stats[0]))\n",
    "            p_X_lls.append(float(stats[1]))\n",
    "            p_Y_lls.append(float(stats[2]))\n",
    "            p_Y_X_lls.append(float(stats[3]))\n",
    "            \n",
    "    assert len(p_X_Y_lls) == 5\n",
    "    assert len(p_X_lls) == 5\n",
    "    assert len(p_Y_lls) == 5\n",
    "    assert len(p_Y_X_lls) == 5\n",
    "    \n",
    "    return numpy.array(p_X_Y_lls), numpy.array(p_X_lls), numpy.array(p_Y_lls), numpy.array(p_Y_X_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-26.85714962 -26.65849524 -26.85600933 -26.61176421 -26.62904252]\n",
      "[-23.1369752  -22.76179664 -23.14640876 -22.94594425 -22.86228867]\n",
      "[-4.62170623 -4.71037673 -4.59397574 -4.5913171  -4.636254  ]\n",
      "[-3.72017441 -3.8966986  -3.70960057 -3.66581996 -3.76675385]\n",
      "[-28.42492085 -30.35267217 -28.54861664 -29.68318685 -30.37089305]\n",
      "[-23.97000886 -25.86773568 -24.03973844 -25.0265959  -25.76909386]\n",
      "[-4.59778773 -4.65549616 -4.68432662 -4.64594702 -4.67789959]\n",
      "[-4.45491199 -4.48493649 -4.5088782  -4.65659095 -4.60179918]\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    file_path = '/home/valerio/Downloads/newcsn/l0.6ts0/arts.log'\n",
    "    with open(file_path, 'r') as f:\n",
    "        log_contents = f.read()\n",
    "        \n",
    "    train_X_Y, train_X, train_Y, train_Y_X = parse_ll_from_log(log_contents, 'Train:', 5)\n",
    "    print(train_X_Y)\n",
    "    print(train_X)\n",
    "    print(train_Y)\n",
    "    print(train_Y_X)\n",
    "    \n",
    "    test_X_Y, test_X, test_Y, test_Y_X = parse_ll_from_log(log_contents, 'Test:', 5)\n",
    "    print(test_X_Y)\n",
    "    print(test_X)\n",
    "    print(test_Y)\n",
    "    print(test_Y_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_scores_from_log(log_str, stat_prefix='Accuracy', n_folds=5, newline='\\n'):\n",
    "    scores = []\n",
    "    lines = log_str.split(newline)\n",
    "    for line in lines:\n",
    "        if stat_prefix in line:\n",
    "            stats = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "            if len(stats) == n_folds:\n",
    "                scores.extend([float(s) for s in stats])\n",
    "                \n",
    "    assert len(scores) == n_folds * 2\n",
    "    return numpy.array(scores[:n_folds]), numpy.array(scores[n_folds:])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.385391  0.411938  0.418159  0.414396  0.394681]\n",
      "[ 0.386499  0.406131  0.424784  0.414603  0.402825]\n",
      "[ 0.934836  0.937953  0.936771  0.936754  0.935392]\n",
      "[ 0.936402  0.938133  0.938878  0.938066  0.937217]\n",
      "[ 0.303738  0.315965  0.329325  0.332219  0.301471]\n",
      "[ 0.293057  0.303941  0.328657  0.323529  0.299465]\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    file_path = '/home/valerio/Downloads/newcsn/l0.6ts0/arts.log'\n",
    "    with open(file_path, 'r') as f:\n",
    "        log_contents = f.read()\n",
    "        \n",
    "    acc_mpe, acc_marg = parse_scores_from_log(log_contents, 'Accuracy', 5)\n",
    "    print(acc_mpe)\n",
    "    print(acc_marg)\n",
    "    \n",
    "    ham_mpe, ham_marg = parse_scores_from_log(log_contents, 'Hamming Score', 5)\n",
    "    print(ham_mpe)\n",
    "    print(ham_marg)\n",
    "    \n",
    "    ext_mpe, ext_marg = parse_scores_from_log(log_contents, 'Exact match', 5)\n",
    "    print(ext_mpe)\n",
    "    print(ext_marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_stats_from_log(log_path, n_folds=5, newline='\\n'):\n",
    "    \"\"\"\n",
    "    From a string representing a log file content,\n",
    "    Extract these information:\n",
    "    For each fold:\n",
    "        - train log likelihoods:\n",
    "            - p(X, Y)\n",
    "            - p(X)\n",
    "            - p(Y)\n",
    "            - p(Y|X)\n",
    "        - test log likelihoods:\n",
    "            - p(X, Y)\n",
    "            - p(X)\n",
    "            - p(Y)\n",
    "            - p(Y|X)\n",
    "        - MPE scores:\n",
    "            - accuracy\n",
    "            - hamming loss\n",
    "            - exact match\n",
    "        - MARG scores:\n",
    "            - accuracy\n",
    "            - hamming loss\n",
    "            - exact match\n",
    "    they are put into a ExpStats namedtuple\n",
    "    \"\"\"\n",
    "    log_str = None\n",
    "    with open(log_path, 'r') as log_file:\n",
    "        log_str = log_file.read()\n",
    "        \n",
    "    train_X_Y, train_X, train_Y, train_Y_X = parse_ll_from_log(log_str, 'Train:', n_folds=n_folds, newline=newline)\n",
    "    test_X_Y, test_X, test_Y, test_Y_X = parse_ll_from_log(log_str, 'Test:', n_folds=n_folds, newline=newline)\n",
    "    \n",
    "    acc_mpe, acc_marg = parse_scores_from_log(log_str, 'Accuracy', n_folds=n_folds, newline=newline)\n",
    "    ham_mpe, ham_marg = parse_scores_from_log(log_str, 'Hamming Score', n_folds=n_folds, newline=newline)\n",
    "    ext_mpe, ext_marg = parse_scores_from_log(log_str, 'Exact match', n_folds=n_folds, newline=newline)\n",
    "    \n",
    "    return ExpStats(train_X_Y, train_X, train_Y, train_Y_X, \n",
    "                   test_X_Y, test_X, test_Y, test_Y_X,\n",
    "                   acc_mpe, ham_mpe, ext_mpe,\n",
    "                   acc_marg, ham_marg, ext_marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(exp_stats):\n",
    "    print('train log p(X,Y):\\t', exp_stats.train_X_Y)\n",
    "    print('train log p(X):\\t', exp_stats.train_X)\n",
    "    print('train log p(Y):\\t', exp_stats.train_Y)\n",
    "    print('train log p(Y|X):\\t', exp_stats.train_Y_X)\n",
    "\n",
    "    print('test log p(X,Y):\\t', exp_stats.test_X_Y)\n",
    "    print('test log p(X):\\t', exp_stats.test_X)\n",
    "    print('test log p(Y):\\t', exp_stats.test_Y)\n",
    "    print('test log p(Y|X):\\t', exp_stats.test_Y_X)\n",
    "    \n",
    "    print('accuracy MPE:\\t', exp_stats.acc_mpe)\n",
    "    print('hamming MPE:\\t', exp_stats.ham_mpe)\n",
    "    print('extact match MPE:\\t', exp_stats.ext_mpe)\n",
    "    \n",
    "    print('accuracy Marg:\\t', exp_stats.acc_marg)\n",
    "    print('hamming Marg:\\t', exp_stats.ham_marg)\n",
    "    print('extact match marg:\\t', exp_stats.ext_marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log p(X,Y):\t [-26.85714962 -26.65849524 -26.85600933 -26.61176421 -26.62904252]\n",
      "train log p(X):\t [-23.1369752  -22.76179664 -23.14640876 -22.94594425 -22.86228867]\n",
      "train log p(Y):\t [-4.62170623 -4.71037673 -4.59397574 -4.5913171  -4.636254  ]\n",
      "train log p(Y|X):\t [-3.72017441 -3.8966986  -3.70960057 -3.66581996 -3.76675385]\n",
      "test log p(X,Y):\t [-28.42492085 -30.35267217 -28.54861664 -29.68318685 -30.37089305]\n",
      "test log p(X):\t [-23.97000886 -25.86773568 -24.03973844 -25.0265959  -25.76909386]\n",
      "test log p(Y):\t [-4.59778773 -4.65549616 -4.68432662 -4.64594702 -4.67789959]\n",
      "test log p(Y|X):\t [-4.45491199 -4.48493649 -4.5088782  -4.65659095 -4.60179918]\n",
      "accuracy MPE:\t [ 0.385391  0.411938  0.418159  0.414396  0.394681]\n",
      "hamming MPE:\t [ 0.934836  0.937953  0.936771  0.936754  0.935392]\n",
      "extact match MPE:\t [ 0.303738  0.315965  0.329325  0.332219  0.301471]\n",
      "accuracy Marg:\t [ 0.386499  0.406131  0.424784  0.414603  0.402825]\n",
      "hamming Marg:\t [ 0.936402  0.938133  0.938878  0.938066  0.937217]\n",
      "extact match marg:\t [ 0.293057  0.303941  0.328657  0.323529  0.299465]\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    file_path = '/home/valerio/Downloads/newcsn/l0.6ts0/arts.log'\n",
    "    exp_stats = parse_stats_from_log(file_path)\n",
    "    print_stats(exp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    #'arts', \n",
    "            'birds', 'business', 'cal', 'emotions', 'flags', 'health', 'human', 'plant', 'scene', 'yeast']\n",
    "\n",
    "def parse_stats_for_exp(exp_dir, datasets=DATASETS, n_folds=5, newline='\\n'):\n",
    "    \"\"\"\n",
    "    Parse the stats for each dataset log file in a dir\n",
    "    \"\"\"\n",
    "    stats_dict = {}\n",
    "    \n",
    "    for d in datasets:\n",
    "        print('\\n\\tconsidering dataset {}'.format(d))\n",
    "        data_path = os.path.join(exp_dir, '{}.log'.format(d))\n",
    "        exp_stats = parse_stats_from_log(data_path, n_folds=n_folds, newline=newline)\n",
    "        stats_dict[d] = exp_stats\n",
    "        \n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene\n",
      "train log p(X,Y):\t [-100.11225567  -99.78257184 -100.15591744 -100.2068322  -100.13090683]\n",
      "train log p(X):\t [-98.54349561 -98.23735346 -98.5940657  -98.6457224  -98.56100839]\n",
      "train log p(Y):\t [-2.19082433 -2.17127021 -2.19394491 -2.18800314 -2.18144029]\n",
      "train log p(Y|X):\t [-1.56876006 -1.54521838 -1.56185175 -1.5611098  -1.56989844]\n",
      "test log p(X,Y):\t [-103.1361335  -104.55640006 -102.8798233  -102.4054884  -102.72650493]\n",
      "test log p(X):\t [-101.06684144 -102.20336878 -100.22905807 -100.18544097 -100.30304743]\n",
      "test log p(Y):\t [-2.16581192 -2.25711744 -2.1538311  -2.17857825 -2.20371779]\n",
      "test log p(Y|X):\t [-2.06929206 -2.35303128 -2.65076522 -2.22004743 -2.4234575 ]\n",
      "accuracy MPE:\t [ 0.661826  0.664592  0.666321  0.660083  0.635764]\n",
      "hamming MPE:\t [ 0.881743  0.882089  0.883126  0.880804  0.872222]\n",
      "extact match MPE:\t [ 0.582988  0.580913  0.60166   0.5842    0.554167]\n",
      "accuracy Marg:\t [ 0.665629  0.673237  0.672545  0.675329  0.631597]\n",
      "hamming Marg:\t [ 0.883817  0.886584  0.885201  0.887734  0.870833]\n",
      "extact match marg:\t [ 0.595436  0.595436  0.607884  0.611227  0.552083]\n",
      "arts\n",
      "train log p(X,Y):\t [-26.85714962 -26.65849524 -26.85600933 -26.61176421 -26.62904252]\n",
      "train log p(X):\t [-23.1369752  -22.76179664 -23.14640876 -22.94594425 -22.86228867]\n",
      "train log p(Y):\t [-4.62170623 -4.71037673 -4.59397574 -4.5913171  -4.636254  ]\n",
      "train log p(Y|X):\t [-3.72017441 -3.8966986  -3.70960057 -3.66581996 -3.76675385]\n",
      "test log p(X,Y):\t [-28.42492085 -30.35267217 -28.54861664 -29.68318685 -30.37089305]\n",
      "test log p(X):\t [-23.97000886 -25.86773568 -24.03973844 -25.0265959  -25.76909386]\n",
      "test log p(Y):\t [-4.59778773 -4.65549616 -4.68432662 -4.64594702 -4.67789959]\n",
      "test log p(Y|X):\t [-4.45491199 -4.48493649 -4.5088782  -4.65659095 -4.60179918]\n",
      "accuracy MPE:\t [ 0.385391  0.411938  0.418159  0.414396  0.394681]\n",
      "hamming MPE:\t [ 0.934836  0.937953  0.936771  0.936754  0.935392]\n",
      "extact match MPE:\t [ 0.303738  0.315965  0.329325  0.332219  0.301471]\n",
      "accuracy Marg:\t [ 0.386499  0.406131  0.424784  0.414603  0.402825]\n",
      "hamming Marg:\t [ 0.936402  0.938133  0.938878  0.938066  0.937217]\n",
      "extact match marg:\t [ 0.293057  0.303941  0.328657  0.323529  0.299465]\n",
      "cal\n",
      "train log p(X,Y):\t [-47.84352102 -47.13038598 -47.6850303  -47.61707794 -47.5381562 ]\n",
      "train log p(X):\t [-5.96100797 -5.64511394 -5.76851101 -5.69640031 -5.90845064]\n",
      "train log p(Y):\t [-42.36567172 -42.05549316 -42.38628444 -42.40521035 -42.09442356]\n",
      "train log p(Y|X):\t [-41.88251305 -41.48527204 -41.91651929 -41.92067764 -41.62970556]\n",
      "test log p(X,Y):\t [-56.97881805 -61.52883457 -57.6998384  -57.99660304 -57.19432622]\n",
      "test log p(X):\t [-6.83055486 -8.55787697 -7.59452218 -7.89208379 -6.48619715]\n",
      "test log p(Y):\t [-48.38926282 -51.34463906 -48.3459723  -48.52636303 -50.07788633]\n",
      "test log p(Y|X):\t [-50.1482632  -52.9709576  -50.10531622 -50.10451925 -50.70812907]\n",
      "accuracy MPE:\t [ 0.190687  0.205808  0.175133  0.185814  0.180503]\n",
      "hamming MPE:\t [ 0.861955  0.843291  0.84546   0.838046  0.859138]\n",
      "extact match MPE:\t [ 0.  0.  0.  0.  0.]\n",
      "accuracy Marg:\t [ 0.225566  0.199127  0.207079  0.180882  0.203891]\n",
      "hamming Marg:\t [ 0.867361  0.859622  0.86      0.855     0.861839]\n",
      "extact match marg:\t [ 0.  0.  0.  0.  0.]\n",
      "human\n",
      "train log p(X,Y):\t [-130.10174823 -130.00220724 -130.04189869 -130.43323208 -130.45934706]\n",
      "train log p(X):\t [-127.13207437 -127.05564779 -127.06622702 -127.4641643  -127.48677954]\n",
      "train log p(Y):\t [-3.11828038 -3.13859445 -3.13525161 -3.13112774 -3.1151526 ]\n",
      "train log p(Y|X):\t [-2.96967386 -2.94655945 -2.97567167 -2.96906778 -2.97256752]\n",
      "test log p(X,Y):\t [-135.79636012 -135.94958896 -135.78515562 -134.40194361 -133.81794214]\n",
      "test log p(X):\t [-132.61968849 -132.88107459 -132.60104625 -131.18352193 -130.61071782]\n",
      "test log p(Y):\t [-3.18011292 -3.04860699 -3.15460164 -3.12732038 -3.17129876]\n",
      "test log p(Y|X):\t [-3.17667163 -3.06851437 -3.18410938 -3.21842168 -3.20722432]\n",
      "accuracy MPE:\t [ 0.311495  0.324759  0.291734  0.294015  0.309543]\n",
      "hamming MPE:\t [ 0.893546  0.899058  0.891764  0.89349   0.894816]\n",
      "extact match MPE:\t [ 0.268489  0.27492   0.243156  0.252818  0.26129 ]\n",
      "accuracy Marg:\t [ 0.302921  0.332262  0.294149  0.25416   0.311962]\n",
      "hamming Marg:\t [ 0.892857  0.901011  0.893145  0.888774  0.895046]\n",
      "extact match marg:\t [ 0.255627  0.278135  0.238325  0.207729  0.264516]\n",
      "plant\n",
      "train log p(X,Y):\t [-95.58111949 -95.86588794 -96.35820574 -95.62772347 -95.95749516]\n",
      "train log p(X):\t [-93.19814837 -93.41996814 -93.97653898 -93.14007491 -93.56678187]\n",
      "train log p(Y):\t [-2.95167462 -2.95640805 -2.9645475  -2.96681836 -2.97546788]\n",
      "train log p(Y|X):\t [-2.38297112 -2.44591979 -2.38166676 -2.48764857 -2.39071329]\n",
      "test log p(X,Y):\t [-114.54355441 -113.07662792 -111.41303714 -114.02846103 -113.42380267]\n",
      "test log p(X):\t [-111.06123718 -109.93765725 -108.28228152 -110.88816314 -110.18947507]\n",
      "test log p(Y):\t [-3.03174504 -3.01572364 -2.96474871 -2.92833453 -2.91553171]\n",
      "test log p(Y|X):\t [-3.48231723 -3.13897067 -3.13075562 -3.1402979  -3.2343276 ]\n",
      "accuracy MPE:\t [ 0.34687   0.346088  0.360684  0.37094   0.346154]\n",
      "hamming MPE:\t [ 0.886633  0.885204  0.890171  0.889744  0.887607]\n",
      "extact match MPE:\t [ 0.329949  0.331633  0.323077  0.353846  0.328205]\n",
      "accuracy Marg:\t [ 0.331641  0.346088  0.337607  0.337607  0.330769]\n",
      "hamming Marg:\t [ 0.884095  0.886054  0.885897  0.884615  0.885043]\n",
      "extact match marg:\t [ 0.314721  0.326531  0.307692  0.323077  0.312821]\n",
      "emotions\n",
      "train log p(X,Y):\t [-26.20989937 -25.8636526  -25.77160558 -25.99682828 -26.17489011]\n",
      "train log p(X):\t [-23.91293451 -23.67515438 -23.65600351 -23.74004977 -23.8879151 ]\n",
      "train log p(Y):\t [-2.83570773 -2.82188149 -2.79135222 -2.82806043 -2.84099863]\n",
      "train log p(Y|X):\t [-2.29696486 -2.18849822 -2.11560207 -2.25677851 -2.28697501]\n",
      "test log p(X,Y):\t [-28.79493467 -30.41029836 -29.74853733 -30.3882927  -28.06213068]\n",
      "test log p(X):\t [-26.0757485  -27.19483569 -26.97366066 -27.5139348  -25.45104229]\n",
      "test log p(Y):\t [-2.89286608 -2.77742393 -2.94443588 -2.8916102  -2.72415054]\n",
      "test log p(Y|X):\t [-2.71918616 -3.21546267 -2.77487668 -2.8743579  -2.61108838]\n",
      "accuracy MPE:\t [ 0.472269  0.508683  0.526891  0.474153  0.515819]\n",
      "hamming MPE:\t [ 0.732493  0.747899  0.759104  0.724576  0.742938]\n",
      "extact match MPE:\t [ 0.184874  0.277311  0.277311  0.262712  0.305085]\n",
      "accuracy Marg:\t [ 0.460784  0.45028   0.497199  0.47387   0.469915]\n",
      "hamming Marg:\t [ 0.7507    0.757703  0.764706  0.75565   0.761299]\n",
      "extact match marg:\t [ 0.210084  0.184874  0.201681  0.254237  0.262712]\n",
      "flags\n",
      "train log p(X,Y):\t [-9.7043003  -9.74445277 -9.61255559 -9.64695603 -9.87314018]\n",
      "train log p(X):\t [-6.79732067 -6.86875132 -6.76973694 -6.7381361  -6.82580516]\n",
      "train log p(Y):\t [-3.76885968 -3.73796438 -3.70146151 -3.70460754 -3.80120952]\n",
      "train log p(Y|X):\t [-2.90697963 -2.87570144 -2.84281866 -2.90881994 -3.04733503]\n",
      "test log p(X,Y):\t [-11.15974002 -11.64118497 -12.44799897 -12.02990131 -10.96014309]\n",
      "test log p(X):\t [-7.20566471 -7.52346371 -8.01502589 -7.70651294 -7.41626709]\n",
      "test log p(Y):\t [-3.82759166 -3.91677038 -4.17906559 -4.05454914 -3.74480215]\n",
      "test log p(Y|X):\t [-3.95407532 -4.11772126 -4.43297308 -4.32338837 -3.543876  ]\n",
      "accuracy MPE:\t [ 0.524048  0.498352  0.539988  0.528446  0.622807]\n",
      "hamming MPE:\t [ 0.682143  0.663004  0.692308  0.672932  0.740602]\n",
      "extact match MPE:\t [ 0.2       0.153846  0.179487  0.210526  0.315789]\n",
      "accuracy Marg:\t [ 0.539464  0.534676  0.555495  0.53985   0.595614]\n",
      "hamming Marg:\t [ 0.692857  0.681319  0.714286  0.680451  0.740602]\n",
      "extact match marg:\t [ 0.15      0.205128  0.179487  0.184211  0.236842]\n",
      "birds\n",
      "train log p(X,Y):\t [-38.62538652 -38.56117211 -38.02959539 -37.76557398 -37.96159637]\n",
      "train log p(X):\t [-36.34803223 -36.43060236 -35.82220328 -35.67161078 -35.79214002]\n",
      "train log p(Y):\t [-3.67334521 -3.60084337 -3.62437348 -3.58560841 -3.53219685]\n",
      "train log p(Y|X):\t [-2.27735429 -2.13056976 -2.20739211 -2.0939632  -2.16945635]\n",
      "test log p(X,Y):\t [-45.55682204 -43.79546414 -46.69700246 -48.65483862 -48.39615411]\n",
      "test log p(X):\t [-42.57420244 -40.55426767 -43.35794417 -44.93351583 -44.6313436 ]\n",
      "test log p(Y):\t [-3.35635946 -3.57548812 -3.69423603 -3.69455168 -3.96980232]\n",
      "test log p(Y|X):\t [-2.98261959 -3.24119647 -3.33905829 -3.7213228  -3.76481051]\n",
      "accuracy MPE:\t [ 0.199359  0.149483  0.209561  0.185788  0.236979]\n",
      "hamming MPE:\t [ 0.933198  0.921257  0.928193  0.922481  0.928454]\n",
      "extact match MPE:\t [ 0.115385   0.0620155  0.100775   0.100775   0.140625 ]\n",
      "accuracy Marg:\t [ 0.199359  0.149483  0.209561  0.185788  0.236979]\n",
      "hamming Marg:\t [ 0.933198  0.921257  0.928193  0.922481  0.928454]\n",
      "extact match marg:\t [ 0.115385   0.0620155  0.100775   0.100775   0.140625 ]\n",
      "business\n",
      "train log p(X,Y):\t [-18.98063005 -18.86251016 -18.52317187 -19.08767016 -18.8278306 ]\n",
      "train log p(X):\t [-17.12571493 -17.02592134 -16.68093677 -17.22897032 -16.95430913]\n",
      "train log p(Y):\t [-2.33266923 -2.30522974 -2.32804474 -2.31278003 -2.29292182]\n",
      "train log p(Y|X):\t [-1.85491512 -1.83658883 -1.8422351  -1.85869985 -1.87352148]\n",
      "test log p(X,Y):\t [-20.46293907 -21.02593143 -22.10833355 -19.92713995 -21.18333333]\n",
      "test log p(X):\t [-17.97434686 -18.63815631 -19.36328688 -17.27851953 -18.47351794]\n",
      "test log p(Y):\t [-2.23773471 -2.36688149 -2.27928944 -2.35831053 -2.42072127]\n",
      "test log p(Y|X):\t [-2.48859222 -2.38777512 -2.74504667 -2.64862042 -2.70981539]\n",
      "accuracy MPE:\t [ 0.721515  0.704756  0.70968   0.715445  0.695849]\n",
      "hamming MPE:\t [ 0.973856  0.972373  0.973027  0.972733  0.970919]\n",
      "extact match MPE:\t [ 0.574421  0.553723  0.55506   0.566905  0.545495]\n",
      "accuracy Marg:\t [ 0.716079  0.703425  0.704947  0.712579  0.691114]\n",
      "hamming Marg:\t [ 0.973856  0.972626  0.973354  0.973238  0.971469]\n",
      "extact match marg:\t [ 0.567291  0.54971   0.549264  0.558876  0.533452]\n",
      "health\n",
      "train log p(X,Y):\t [-17.72133438 -17.70470205 -17.69328991 -17.61374293 -17.49884848]\n",
      "train log p(X):\t [-14.88976024 -14.89495935 -14.90204746 -14.79385754 -14.70285743]\n",
      "train log p(Y):\t [-3.59451443 -3.58828044 -3.59189758 -3.58637952 -3.59139444]\n",
      "train log p(Y|X):\t [-2.83157414 -2.80974269 -2.79124245 -2.81988539 -2.79599105]\n",
      "test log p(X,Y):\t [-18.40784871 -18.47013345 -18.74014073 -19.01912869 -19.44894425]\n",
      "test log p(X):\t [-15.27748986 -15.32610227 -15.45121706 -15.74026814 -16.20564842]\n",
      "test log p(Y):\t [-3.61223119 -3.60289947 -3.61402436 -3.63459478 -3.60078969]\n",
      "test log p(Y|X):\t [-3.13035885 -3.14403119 -3.28892366 -3.27886055 -3.24329584]\n",
      "accuracy MPE:\t [ 0.575021  0.573405  0.556148  0.582811  0.576885]\n",
      "hamming MPE:\t [ 0.962812  0.96252   0.960891  0.963081  0.962517]\n",
      "extact match MPE:\t [ 0.450054  0.445953  0.425856  0.443237  0.446196]\n",
      "accuracy Marg:\t [ 0.572021  0.571     0.545239  0.572453  0.571332]\n",
      "hamming Marg:\t [ 0.96422   0.963912  0.961926  0.963776  0.963689]\n",
      "extact match marg:\t [ 0.429425  0.43346   0.391635  0.420967  0.428804]\n",
      "yeast\n",
      "train log p(X,Y):\t [-26.64638336 -26.60771702 -26.61731903 -26.63078738 -27.16625895]\n",
      "train log p(X):\t [-22.38466295 -22.38420546 -22.40924908 -22.46107163 -22.63404098]\n",
      "train log p(Y):\t [-4.46761095 -4.45088412 -4.43643642 -4.43764814 -4.69460434]\n",
      "train log p(Y|X):\t [-4.26172041 -4.22351156 -4.20806996 -4.16971575 -4.53221797]\n",
      "test log p(X,Y):\t [-27.51295018 -27.68599561 -27.60639406 -27.78572656 -28.13095962]\n",
      "test log p(X):\t [-22.8756583  -22.98683751 -22.80057983 -22.70433227 -23.30442997]\n",
      "test log p(Y):\t [-4.40193689 -4.47039431 -4.51221588 -4.53587016 -4.74612703]\n",
      "test log p(Y|X):\t [-4.63729188 -4.6991581  -4.80581423 -5.08139429 -4.82652965]\n",
      "accuracy MPE:\t [ 0.478465  0.497256  0.47351   0.488307  0.474367]\n",
      "hamming MPE:\t [ 0.767267  0.769776  0.761659  0.770038  0.764671]\n",
      "extact match MPE:\t [ 0.167355  0.204545  0.163223  0.180124  0.161826]\n",
      "accuracy Marg:\t [ 0.465427  0.482134  0.453039  0.46191   0.436503]\n",
      "hamming Marg:\t [ 0.778926  0.779368  0.770366  0.777876  0.779194]\n",
      "extact match marg:\t [ 0.103306   0.152893   0.119835   0.0890269  0.0394191]\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    exp_dir = '/home/valerio/Downloads/newcsn/l0.6ts0'\n",
    "    \n",
    "    stats = parse_stats_for_exp(exp_dir)\n",
    "    for k, v in stats.items():\n",
    "        print(k)\n",
    "        print_stats(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TREE_STRUCTURES = [0, 1, 2, 3]\n",
    "CL_CSN = ['0.6', '1.0']\n",
    "Y_LEAVES = [False, True]\n",
    "\n",
    "def parse_stats_for_models_exps(exp_dir, \n",
    "                                tree_structures=TREE_STRUCTURES,\n",
    "                                splits=CL_CSN,\n",
    "                                leaves=Y_LEAVES,\n",
    "                                datasets=DATASETS, \n",
    "                                n_folds=5, \n",
    "                                newline='\\n'):\n",
    "    \n",
    "    dataset_assoc = defaultdict(dict)\n",
    "    model_assoc = {}\n",
    "    \n",
    "    for ts in tree_structures:\n",
    "        for s in splits:\n",
    "            exp_prefix = 'l{}ts{}'.format(s, ts)\n",
    "            for l in leaves:\n",
    "                if l:\n",
    "                    exp_prefix += 'l'\n",
    "                print('\\n\\nConsidering exp: {}'.format(exp_prefix))\n",
    "                exp_path = os.path.join(exp_dir, exp_prefix)\n",
    "                \n",
    "                stats_dict = parse_stats_for_exp(exp_path, datasets=datasets, n_folds=n_folds, newline=newline)\n",
    "                \n",
    "                # for k, v in stats_dict.items():\n",
    "                #    print('\\t{}'.format(k))\n",
    "                #    print_stats(v)\n",
    "                \n",
    "                model_assoc[exp_prefix] = stats_dict\n",
    "                \n",
    "                for dataset, v in stats_dict.items():\n",
    "                    dataset_assoc[dataset][exp_prefix] = v\n",
    "                    \n",
    "    return dataset_assoc, model_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Considering exp: l0.6ts0\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts0l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts0\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts0l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts1\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts1l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts1\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts1l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts2\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts2l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts2\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts2l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts3\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts3l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts3\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts3l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    exp_dir = '/home/valerio/Downloads/newcsn'\n",
    "    dataset_assoc, model_assoc = parse_stats_for_models_exps(exp_dir, datasets=DATASETS)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_boxplot_stat(model_assoc, stat_names=['train_X_Y', 'test_X_Y']):\n",
    "    \n",
    "    n_models = len(model_assoc)\n",
    "    n_stats = len(stat_names)\n",
    "    \n",
    "    labels = list(k for k in model_assoc)\n",
    "        \n",
    "    fig, axes = pyplot.subplots(nrows=1, ncols=n_stats, figsize=(12, 12))\n",
    "\n",
    "    for j in range(n_stats):\n",
    "        print('Considering stat {}'.format(stat_names[j]))\n",
    "        data = []\n",
    "        for model, stats in model_assoc.items():\n",
    "            data.append(getattr(stats, stat_names[j]))\n",
    "        data = numpy.array(data).T\n",
    "\n",
    "    \n",
    "        # for i in range(n_models):\n",
    "        axes[j].boxplot(data, labels=labels)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Considering exp: l0.6ts0\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts0l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts0\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts0l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts1\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts1l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts1\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts1l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts2\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts2l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts2\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts2l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts3\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l0.6ts3l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts3\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "\n",
      "\n",
      "Considering exp: l1.0ts3l\n",
      "\n",
      "\tconsidering dataset birds\n",
      "\n",
      "\tconsidering dataset business\n",
      "\n",
      "\tconsidering dataset cal\n",
      "\n",
      "\tconsidering dataset emotions\n",
      "\n",
      "\tconsidering dataset flags\n",
      "\n",
      "\tconsidering dataset health\n",
      "\n",
      "\tconsidering dataset human\n",
      "\n",
      "\tconsidering dataset plant\n",
      "\n",
      "\tconsidering dataset scene\n",
      "\n",
      "\tconsidering dataset yeast\n",
      "Considering stat train_X_Y\n",
      "Considering stat test_X_Y\n"
     ]
    }
   ],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    exp_dir = '/home/valerio/Downloads/newcsn'\n",
    "    dataset_assoc, model_assoc = parse_stats_for_models_exps(exp_dir, datasets=DATASETS)\n",
    "    \n",
    "    plot_model_boxplot_stat(dataset_assoc['plant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
